{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textgenrnn & keras attention mechanism.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVsatKMbxbyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "8a6e893c-93ad-4146-ea32-5efea4d6ef0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2vI82rBxhX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install textgenrnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_olDNxWc7MFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJvSdR0LxodK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = \"/content/drive/My Drive/Christmas-Carol-Generator-master/lyrics/All I Want For Christmas Is You.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3InYwr-O3TaH",
        "colab_type": "text"
      },
      "source": [
        "## textgenrnn\n",
        "https://github.com/minimaxir/textgenrnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udXN6Ckxsgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn()\n",
        "textgen.train_from_file(file, num_epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7NA_K5EyVes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "33e35825-1266-457c-96b4-3889bb2903f4"
      },
      "source": [
        "for _ in range(5):\n",
        "  textgen.generate()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I just wanna keep on waiting\n",
            "\n",
            "I don't want a lot for Christmas\n",
            "\n",
            "There upon the fireplace\n",
            "\n",
            "I don't want a lot for Christmas\n",
            "\n",
            "All I want for Christmas is you, baby\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XuM1oAr3bUJ",
        "colab_type": "text"
      },
      "source": [
        "## keras attention mechanism\n",
        "https://github.com/philipperemy/keras-attention-mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqRQGGCPy2lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Lambda, dot, Activation, concatenate\n",
        "\n",
        "\n",
        "def attention_3d_block(hidden_states):\n",
        "    # @author: felixhao28.\n",
        "    # hidden_states.shape = (batch_size, time_steps, hidden_size)\n",
        "    hidden_size = int(hidden_states.shape[2])\n",
        "    # Inside dense layer\n",
        "    #              hidden_states            dot               W            =>           score_first_part\n",
        "    # (batch_size, time_steps, hidden_size) dot (hidden_size, hidden_size) => (batch_size, time_steps, hidden_size)\n",
        "    # W is the trainable weight matrix of attention Luong's multiplicative style score\n",
        "    score_first_part = Dense(hidden_size, use_bias=False, name='attention_score_vec')(hidden_states)\n",
        "    #            score_first_part           dot        last_hidden_state     => attention_weights\n",
        "    # (batch_size, time_steps, hidden_size) dot   (batch_size, hidden_size)  => (batch_size, time_steps)\n",
        "    h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(hidden_states)\n",
        "    score = dot([score_first_part, h_t], [2, 1], name='attention_score')\n",
        "    attention_weights = Activation('softmax', name='attention_weight')(score)\n",
        "    # (batch_size, time_steps, hidden_size) dot (batch_size, time_steps) => (batch_size, hidden_size)\n",
        "    context_vector = dot([hidden_states, attention_weights], [1, 1], name='context_vector')\n",
        "    pre_activation = concatenate([context_vector, h_t], name='attention_output')\n",
        "    attention_vector = Dense(128, use_bias=False, activation='tanh', name='attention_vector')(pre_activation)\n",
        "    return attention_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvjNUMNj2RT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keract import get_activations\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "INPUT_DIM = 100\n",
        "TIME_STEPS = 20\n",
        "\n",
        "def get_data_recurrent(n, time_steps, input_dim, attention_column=10):\n",
        "    \"\"\"\n",
        "    Data generation. x is purely random except that it's first value equals the target y.\n",
        "    In practice, the network should learn that the target = x[attention_column].\n",
        "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
        "    :param n: the number of samples to retrieve.\n",
        "    :param time_steps: the number of time steps of your series.\n",
        "    :param input_dim: the number of dimensions of each element in the series.\n",
        "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
        "    :return: x: model inputs, y: model targets\n",
        "    \"\"\"\n",
        "    x = np.random.randint(input_dim, size=(n, time_steps))\n",
        "    x = np.eye(input_dim)[x]\n",
        "    y = x[:, attention_column, :]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
        "    rnn_out = LSTM(32, return_sequences=True)(inputs)\n",
        "    attention_output = attention_3d_block(rnn_out)\n",
        "    output = Dense(INPUT_DIM, activation='sigmoid', name='output')(attention_output)\n",
        "    m = Model(inputs=[inputs], outputs=[output])\n",
        "    print(m.summary())\n",
        "    return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5gCkx6z5Ijx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "df9c31f9-d55b-4826-a8b6-59dac284380f"
      },
      "source": [
        "n = 300000\n",
        "inputs, outputs = get_data_recurrent(n, TIME_STEPS, INPUT_DIM)\n",
        "\n",
        "m = get_model()\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "m.fit(x=[inputs], y=outputs, epochs=2, batch_size=64, validation_split=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 100)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 20, 32)       17024       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_score_vec (Dense)     (None, 20, 32)       1024        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "last_hidden_state (Lambda)      (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "attention_score (Dot)           (None, 20)           0           attention_score_vec[0][0]        \n",
            "                                                                 last_hidden_state[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "attention_weight (Activation)   (None, 20)           0           attention_score[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "context_vector (Dot)            (None, 32)           0           lstm[0][0]                       \n",
            "                                                                 attention_weight[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_output (Concatenate)  (None, 64)           0           context_vector[0][0]             \n",
            "                                                                 last_hidden_state[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "attention_vector (Dense)        (None, 128)          8192        attention_output[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 100)          12900       attention_vector[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 39,140\n",
            "Trainable params: 39,140\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 300000 samples\n",
            "Epoch 1/2\n",
            "300000/300000 [==============================] - 35s 117us/sample - loss: 1.1309 - accuracy: 0.7668\n",
            "Epoch 2/2\n",
            "300000/300000 [==============================] - 27s 91us/sample - loss: 0.0014 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd9ba6f8dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MremXD5D5LFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_simulations = 10\n",
        "attention_vectors = np.zeros(shape=(num_simulations, TIME_STEPS))\n",
        "for i in range(num_simulations):\n",
        "    testing_inputs_1, testing_outputs = get_data_recurrent(1, TIME_STEPS, INPUT_DIM)\n",
        "    activations = get_activations(m, testing_inputs_1, layer_name='attention_weight')\n",
        "    #activations = K.function([m.layers[0].input], [m.layers[1].output])\n",
        "    attention_vec = np.mean(activations['attention_weight'], axis=0).squeeze()\n",
        "    assert np.abs(np.sum(attention_vec) - 1.0) < 1e-5\n",
        "    attention_vectors[i] = attention_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Pc2qqU6Wc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "27cacbea-8d75-4191-884e-c2651574459c"
      },
      "source": [
        "attention_vector_final = np.mean(attention_vectors, axis=0)\n",
        "attention_df = pd.DataFrame(attention_vector_final, columns=['attention (%)'])\n",
        "attention_df.plot(kind='bar', title='Attention Mechanism as a function of input dimensions.')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAELCAYAAADJF31HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEcmI/w9L/wZnciQhFQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}